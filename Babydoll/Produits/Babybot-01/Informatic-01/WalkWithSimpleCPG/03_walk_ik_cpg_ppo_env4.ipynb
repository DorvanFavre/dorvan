{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import babybot01_env\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "name = 'ppo_spidy_v4_1'\n",
    "env_id = \"Spidy-v4\"\n",
    "n_steps = 1200\n",
    "n_envs = 1\n",
    "\n",
    "policy = 'MlpPolicy'\n",
    "tensorboard_log = f\"./{name}/t_logs/\"\n",
    "path = f\"./{name}/model/{name}\"\n",
    "log_path = f\"./{name}/logs/\"\n",
    "device = 'cpu'\n",
    "\n",
    "def make_env(render_mode:str=None):\n",
    "    e = gym.make(env_id, render_mode=render_mode)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = gym.make(env_id,max_episode_steps=n_steps, render_mode=\"human\")\n",
    "\n",
    "print(\"First Obs\")\n",
    "obs, info = env.reset()\n",
    "print(obs)\n",
    "\n",
    "action = env.action_space.sample()\n",
    "print(action)\n",
    "\n",
    "obs, rew, terminated, truncated, info = env.step(action)\n",
    "print(obs)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    }
   ],
   "source": [
    "train_env = gym.make(env_id, render_mode=\"rgb_array\", max_episode_steps=1000)\n",
    "\n",
    "model = PPO(policy, train_env, batch_size = 60, verbose=0, n_steps=n_steps, tensorboard_log=tensorboard_log)\n",
    "\n",
    "#model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseCallback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInfoCallback\u001b[39;00m(\u001b[43mBaseCallback\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(verbose)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseCallback' is not defined"
     ]
    }
   ],
   "source": [
    "class InfoCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Access the training environment's 'step_info' attribute\n",
    "        \n",
    "        info = self.locals['infos']\n",
    "        info = info[0]\n",
    "\n",
    "        self.logger.record(\"rewards/distance_reward\", info[\"distance_reward\"])\n",
    "        self.logger.record(\"rewards/last_ep_mean_rew\", info[\"last_ep_mean_rew\"])\n",
    "\n",
    "        return True\n",
    "            \n",
    "train_env = Monitor(make_env())\n",
    "eval_env = make_env()\n",
    "\n",
    "eval_callback = EvalCallback(eval_env,\n",
    "                             log_path=log_path, eval_freq=1e5,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "class SaveOnStep(BaseCallback):\n",
    "    def __init__(self, steps: int, path: str):\n",
    "        super().__init__()\n",
    "        self.steps = steps\n",
    "        self.save_path = path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if the current step matches the saving frequency\n",
    "        if self.n_calls % self.steps == 0:\n",
    "            # Save model with the current timestep in the filename\n",
    "\n",
    "            print(f\"Saving model at step {self.n_calls} to {self.save_path}\")\n",
    "            self.model.save(self.save_path)\n",
    "        return True\n",
    "    \n",
    "callbacks = [SaveOnStep(1e5, path), InfoCallback(), eval_callback]\n",
    "\n",
    "model = PPO.load(path,train_env ,device=device)\n",
    "\n",
    "model.learn(total_timesteps=1e7, progress_bar=True, callback=callbacks, reset_num_timesteps=False)\n",
    "\n",
    "model.save(path)\n",
    "\n",
    "train_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.2\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m action \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#action = np.zeros(66)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m obs, reward, terminate, trunc, info \u001b[38;5;241m=\u001b[39m \u001b[43mtest_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminate \u001b[38;5;129;01mor\u001b[39;00m trunc:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/Create_environment/babybot01_env/babybot01_env/envs/spidyv4.py:378\u001b[0m, in \u001b[0;36mSpidyEnvV4.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    376\u001b[0m p\u001b[38;5;241m.\u001b[39mstepSimulation()\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTIME_STEP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Update camera\u001b[39;00m\n\u001b[1;32m    381\u001b[0m cam \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgetDebugVisualizerCamera()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "test_env = gym.make(env_id,max_episode_steps=n_steps, render_mode=\"human\", )\n",
    "model = PPO.load(path)\n",
    "info = {}\n",
    "\n",
    "for episode in range(1):\n",
    "\n",
    "    done = False\n",
    "    obs, info = test_env.reset()\n",
    "    for t in range(n_steps):\n",
    "\n",
    "        action = model.predict(obs)[0]\n",
    "        #action = np.zeros(66)\n",
    "        \n",
    "        obs, reward, terminate, trunc, info = test_env.step(action)\n",
    "    \n",
    "        if terminate or trunc:\n",
    "            break\n",
    "\n",
    "        print(reward)\n",
    "\n",
    "test_env.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show CPG parameters\n",
    "coupling_weights = info['coupling_weights']\n",
    "phase_biases= info['phase_biases']\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize=(12, 6))  # Adjust size if needed\n",
    "\n",
    "im1 = axs[0].imshow(coupling_weights, cmap='viridis', aspect='equal')\n",
    "fig.colorbar(im1, ax=axs[0], orientation='vertical')  # Add a color bar for reference\n",
    "axs[0].set_title(\"coupling_weights\")\n",
    "axs[0].set_xlabel(\"Column Index\")\n",
    "axs[0].set_ylabel(\"Row Index\")\n",
    "axs[0].set_xticks(range(12))\n",
    "axs[0].set_yticks(range(12))\n",
    "\n",
    "im2 = axs[1].imshow(phase_biases, cmap='viridis', aspect='equal')\n",
    "fig.colorbar(im1, ax=axs[1], orientation='vertical')  # Add a color bar for reference\n",
    "axs[1].set_title(\"phase_biases\")\n",
    "axs[1].set_xlabel(\"Column Index\")\n",
    "axs[1].set_ylabel(\"Row Index\")\n",
    "axs[1].set_xticks(range(12))\n",
    "axs[1].set_yticks(range(12))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hostEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
