{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import simple_env\n",
    "from simple_env.wrappers import RelativePosition, NormalizedObservation\n",
    "from gymnasium.wrappers import TimeAwareObservation\n",
    "from stable_baselines3 import DQN, A2C, PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, BaseCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import shutil\n",
    "from typing import Callable\n",
    "\n",
    "name = '01_gridworld'\n",
    "env_name = \"simple_env/ContinuousWorld-v1\"\n",
    "world_size = 300\n",
    "\n",
    "agent = PPO\n",
    "policy = 'MlpPolicy'\n",
    "dir = f\"./{name}\"\n",
    "tensorboard_log = f\"./{name}/t_logs/\"\n",
    "model_path = f\"./{name}/model/best_model.zip\"\n",
    "best_model_save_path = f\"./{name}/model/\"\n",
    "log_path = f\"./{name}/logs/\"\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "def make_env(render_mode = None):\n",
    "    env = gym.make(\n",
    "        env_name,\n",
    "        render_mode = render_mode,\n",
    "        size=world_size, \n",
    "        max_episode_steps=50)\n",
    "    \n",
    "    env = TimeAwareObservation(env, normalize_time=True)\n",
    "    return env\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Setup\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "with open(\"01_gridworld.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "for cell in notebook.cells:\n",
    "    if \"tags\" in cell.metadata and \"setup\" in cell.metadata.tags:\n",
    "        exec(cell.source)\n",
    "\n",
    "env = make_env(render_mode='human')\n",
    "obs, info = env.reset()\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "while not terminated and not truncated:\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    obs, rew, terminated, truncated, info = env.step(action)\n",
    "    print(f\"Action: {action}, Obs: {obs}, rew: {rew}\")\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorvan/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path '01_gridworld/model' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Execute Setup\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "with open(\"01_gridworld.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "for cell in notebook.cells:\n",
    "    if \"tags\" in cell.metadata and \"setup\" in cell.metadata.tags:\n",
    "        exec(cell.source)\n",
    "\n",
    "# Linear Schedule\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return progress_remaining * initial_value\n",
    "    return func\n",
    "\n",
    "# Create model\n",
    "env = make_env()\n",
    "\n",
    "\n",
    "if agent is DQN:\n",
    "    model = DQN(\n",
    "        policy,\n",
    "        env,\n",
    "        verbose=0,\n",
    "        device=device,\n",
    "        tensorboard_log=tensorboard_log,\n",
    "        exploration_fraction=0.5,\n",
    "        learning_rate=linear_schedule(0.0001)\n",
    "    )\n",
    "    \n",
    "elif agent is A2C:\n",
    "    model = A2C(\n",
    "        policy,\n",
    "        env,\n",
    "        verbose=0,\n",
    "        device=device,\n",
    "        tensorboard_log=tensorboard_log,    \n",
    "    )\n",
    "    \n",
    "elif agent is PPO:\n",
    "    model = PPO(\n",
    "        policy,\n",
    "        env,\n",
    "        verbose=0,\n",
    "        device=device,\n",
    "        tensorboard_log=tensorboard_log,    \n",
    "    )\n",
    "\n",
    "# Save\n",
    "shutil.rmtree(dir, ignore_errors=True)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bda797e39347daa0235f530e3b7126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/dorvan/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/\n",
       "stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` \n",
       "wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify \n",
       "these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/dorvan/Documents/dorvan/Babydoll/Produits/Babybot-01/Informatic-01/venv/hostEnv/lib/python3.10/site-packages/\n",
       "stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` \n",
       "wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify \n",
       "these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=10000, episode_reward=2.90 +/- 0.91\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=10000, episode_reward=2.90 +/- 0.91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 29.30 +/- 15.72\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 29.30 +/- 15.72\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=20000, episode_reward=3.23 +/- 1.31\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=20000, episode_reward=3.23 +/- 1.31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 22.30 +/- 13.07\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 22.30 +/- 13.07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=30000, episode_reward=2.97 +/- 0.63\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=30000, episode_reward=2.97 +/- 0.63\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 19.80 +/- 6.32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 19.80 +/- 6.32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=40000, episode_reward=2.55 +/- 0.61\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=40000, episode_reward=2.55 +/- 0.61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 15.50 +/- 6.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 15.50 +/- 6.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=50000, episode_reward=2.99 +/- 1.21\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=50000, episode_reward=2.99 +/- 1.21\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 20.00 +/- 12.12\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 20.00 +/- 12.12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=60000, episode_reward=2.98 +/- 0.62\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=60000, episode_reward=2.98 +/- 0.62\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 20.00 +/- 6.08\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 20.00 +/- 6.08\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=70000, episode_reward=3.19 +/- 1.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=70000, episode_reward=3.19 +/- 1.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 22.00 +/- 11.04\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 22.00 +/- 11.04\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=80000, episode_reward=2.26 +/- 0.74\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=80000, episode_reward=2.26 +/- 0.74\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 12.70 +/- 7.35\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 12.70 +/- 7.35\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=90000, episode_reward=2.94 +/- 0.82\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=90000, episode_reward=2.94 +/- 0.82\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 19.50 +/- 8.16\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 19.50 +/- 8.16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=100000, episode_reward=2.95 +/- 1.03\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=100000, episode_reward=2.95 +/- 1.03\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 19.70 +/- 10.48\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 19.70 +/- 10.48\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute Setup\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "with open(\"01_gridworld.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "for cell in notebook.cells:\n",
    "    if \"tags\" in cell.metadata and \"setup\" in cell.metadata.tags:\n",
    "        exec(cell.source)\n",
    "        \n",
    "# Env and model\n",
    "train_env = make_env()\n",
    "eval_env = make_env()\n",
    "\n",
    "model = agent.load(model_path, train_env, device)\n",
    "\n",
    "# Callbacks\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    eval_freq=1e4,\n",
    "    deterministic=True,\n",
    "    n_eval_episodes=10,\n",
    "    best_model_save_path=best_model_save_path,\n",
    ")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    1e4,\n",
    "    best_model_save_path,\n",
    "    name_prefix=\"checkpoint\"\n",
    ")\n",
    "\n",
    "# Training\n",
    "model.learn(\n",
    "    total_timesteps=1e5,\n",
    "    progress_bar=True,\n",
    "    reset_num_timesteps=False,\n",
    "    \n",
    "    callback=[\n",
    "        eval_callback,\n",
    "        checkpoint_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save and close\n",
    "#model.save(path)\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 2, Obs: [-0.37666667  0.42        0.02      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.34333333  0.42        0.04      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.31  0.42  0.06], Rew: 0.1\n",
      "Action: 2, Obs: [-0.27666667  0.42        0.08      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.24333334  0.42        0.1       ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.21  0.42  0.12], Rew: 0.1\n",
      "Action: 2, Obs: [-0.17666666  0.42        0.14      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.14333333  0.42        0.16      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.11  0.42  0.18], Rew: 0.1\n",
      "Action: 1, Obs: [-0.11        0.38666666  0.2       ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.07666667  0.38666666  0.22      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.07666667  0.35333332  0.24      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.07666667  0.32        0.26      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.07666667  0.28666666  0.28      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.07666667  0.25333333  0.3       ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.07666667  0.22        0.32      ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.04333333  0.22        0.34      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.04333333  0.18666667  0.36      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.04333333  0.15333334  0.38      ], Rew: 0.1\n",
      "Action: 1, Obs: [-0.04333333  0.12        0.4       ], Rew: 0.1\n",
      "Action: 2, Obs: [-0.01  0.12  0.42], Rew: 0.1\n",
      "Action: 1, Obs: [-0.01        0.08666667  0.44      ], Rew: 0.1\n",
      "Action: 2, Obs: [0.02333333 0.08666667 0.46      ], Rew: -0.04\n",
      "Action: 1, Obs: [0.02333333 0.05333333 0.48      ], Rew: 0.1\n",
      "Action: 0, Obs: [-0.01        0.05333333  0.5       ], Rew: 0.04\n",
      "Action: 2, Obs: [0.02333333 0.05333333 0.52      ], Rew: -0.04\n",
      "Action: 0, Obs: [-0.01        0.05333333  0.54      ], Rew: 0.04\n",
      "Action: 2, Obs: [0.02333333 0.05333333 0.56      ], Rew: -0.04\n",
      "Action: 0, Obs: [-0.01        0.05333333  0.58      ], Rew: 0.04\n",
      "Action: 1, Obs: [-0.01  0.02  0.6 ], Rew: 1.1\n"
     ]
    }
   ],
   "source": [
    "# Execute Setup\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "with open(\"01_gridworld.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "for cell in notebook.cells:\n",
    "    if \"tags\" in cell.metadata and \"setup\" in cell.metadata.tags:\n",
    "        exec(cell.source)\n",
    "\n",
    "env = make_env(render_mode='human')\n",
    "obs, info = env.reset()\n",
    "\n",
    "#model = agent.load(best_model_save_path + \"best_model.zip\")\n",
    "model = agent.load(best_model_save_path + \"/checkpoint_60000_steps.zip\")\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "while not terminated and not truncated:\n",
    "    \n",
    "    action, _ = model.predict(obs)\n",
    "    action = int(action)\n",
    "    obs, rew, terminated, truncated, info = env.step(action)\n",
    "    print(f\"Action: {action}, Obs: {obs}, Rew: {rew}\")\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hostEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
